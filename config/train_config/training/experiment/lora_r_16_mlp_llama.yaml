size: "medium"
lora:
  r: 32
  alpha: 18
  dropout: 0.05
  target_modules:
    - "mlp.gate_proj"
    - "mlp.down_proj"
    - "mlp.up_proj"
    - "q_proj"
    - "k_proj"