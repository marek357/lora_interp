name: auto-interpret
layer_idx: 11
k_heap: 50
# k: 32
# r: 4096
k: ${model.k}
r: ${model.r}
train_steps: 5000
batch_size: 10
max_new_tokens: 125
hook_type: "disable"
max_examples_per_latent: 20
latent_interp_batch_size: 10
max_length: 512
max_rows: 10
context_size_each_side: 10
dump_generated: True
dump_analysis: True
dataset_name: "Anthropic/hh-rlhf"
sleep_sec: 0.5
chat_model: "gpt-4o"
chat_model_temperature: 0.0
chat_system_prompt: "You are a helpful assistant."
build_eval_function:
  _target_: src.evals.auto_interp
